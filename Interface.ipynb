{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "YWEhzfcPYQDE"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, gray2rgb\n",
    "from skimage.transform import resize\n",
    "import skimage.io\n",
    "from skimage.io import imsave, imshow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "#import cv2\n",
    "from tensorflow.keras.layers import Input,Dense,Reshape,Conv2D,Dropout,multiply,Dot,Concatenate,subtract,ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization,LeakyReLU,Flatten\n",
    "from tensorflow.keras.layers import Conv2DTranspose as Deconv2d\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "#from google.colab import files\n",
    "from tensorflow.keras import backend as K\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions: \n",
      "\n",
      "Tensorflow 2.1.0\n",
      "Keras 2.2.4-tf\n",
      "Scikit-Image 0.17.2\n",
      "Scikit-Learn 0.23.2\n",
      "Numpy 1.17.4\n",
      "Pandas 0.25.3\n",
      "PIL 7.2.0\n"
     ]
    }
   ],
   "source": [
    "print('Versions: \\n')\n",
    "print('Tensorflow',tf.__version__)\n",
    "print('Keras',tf.keras.__version__)\n",
    "print('Scikit-Image',skimage.__version__)\n",
    "print('Scikit-Learn',sklearn.__version__)\n",
    "print('Numpy',np.__version__)\n",
    "print('Pandas',pd.__version__)\n",
    "print('PIL',Image.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "1OshjbAasXDg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def gen_model():\n",
    "\n",
    "    inputs = tf.keras.layers.Input( shape=( img_size , img_size , 1 ) )\n",
    "\n",
    "    c1 = tf.keras.layers.Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1 )( inputs )\n",
    "    c1 = tf.keras.layers.LeakyReLU()( c1 )\n",
    "    c1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( c1 )\n",
    "    c1 = tf.keras.layers.LeakyReLU()( c1 )\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1)( c1 )\n",
    "    c2 = tf.keras.layers.LeakyReLU()( c2 )\n",
    "    c2 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( c2 )\n",
    "    c2 = tf.keras.layers.LeakyReLU()( c2 )\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 )( c2 )\n",
    "    c3 = tf.keras.layers.LeakyReLU()( c3 )\n",
    "\n",
    "    bottleneck = tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' , padding='same' )( c3 )\n",
    "\n",
    "    concat_1 = tf.keras.layers.Concatenate()( [ bottleneck , c3 ] )\n",
    "    ct3 = tf.keras.layers.Conv2DTranspose( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_1 )\n",
    "\n",
    "    concat_2 = tf.keras.layers.Concatenate()( [ ct3 , c2 ] )\n",
    "    ct2 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_2 )\n",
    "    ct2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( ct2 )\n",
    "\n",
    "    concat_3 = tf.keras.layers.Concatenate()( [ ct2 , c1 ] )\n",
    "    ct1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( concat_3 )\n",
    "    ct1 = tf.keras.layers.Conv2DTranspose( 16 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( ct1 )\n",
    "\n",
    "    ct1 = tf.keras.layers.Conv2DTranspose( 3 , kernel_size=( 1 , 1 ) , strides=1 , activation='relu')( ct1 )\n",
    "\n",
    "    model = tf.keras.models.Model( inputs , ct1 )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "NPIIgDX8sfnI"
   },
   "outputs": [],
   "source": [
    "def disc_model():\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=2, input_shape=( 128 , 128 , 3 ) ),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Conv2D( 64 , kernel_size=( 3, 3 ) , strides=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense( 1 , activation='sigmoid' ) \n",
    "    ]\n",
    "    model = tf.keras.models.Sequential( layers )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = gen_model()\n",
    "discriminator = disc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights('saves/gen_weights2.h5')\n",
    "discriminator.load_weights('saves/dis_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#generatorx = load_model('saves/generatorx.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import PySimpleGUI as sg\n",
    "import os.path\n",
    "\n",
    "generator.load_weights('saves/gen_weights2.h5')\n",
    "discriminator.load_weights('saves/dis_weights2.h5')\n",
    "\n",
    "def colorize_image(image_filename=None, cv2_frame=None):\n",
    "    img1_color = []\n",
    "    # load the input image from disk, scale the pixel intensities to the range [0, 1], and then convert the image from the BGR to Lab color space\n",
    "    image = cv2.imread(image_filename) if image_filename else cv2_frame\n",
    "    scaled = image.astype(\"float32\") / 255.0\n",
    "    lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
    "    #test_image = Image.resize(128,128)\n",
    "    #resize the Lab image to 224x224 (the dimensions the colorization network accepts), split channels, extract the 'L' channel, and then perform mean centering\n",
    "    resized = cv2.resize(lab, (128, 128))\n",
    "    L = cv2.split(resized)[0]\n",
    "    gray_img_array = np.asarray( L )\n",
    "    #colorized = generator(gray_img_array).numpy()\n",
    "    #colorized = (255 * colorized).astype(\"uint8\")\n",
    "    \n",
    "    img1=img_to_array(test_image)\n",
    "    img1_color.append(img1)\n",
    "    img1_color = np.array(img1_color, dtype=float)\n",
    "    img1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
    "    img1_color = img1_color.reshape(img1_color.shape+(1,))\n",
    "    y = generator(img1_color).numpy()\n",
    "\n",
    "    colorized = Image.fromarray( ( y[0] ).astype( 'uint8' ) )\n",
    "    colorized = np.asarray( image )\n",
    "    \n",
    "    \n",
    "    return image, colorized\n",
    "\n",
    "\n",
    "def convert_to_grayscale(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert webcam frame to grayscale\n",
    "    gray_3_channels = np.zeros_like(frame)  # Convert grayscale frame (single channel) to 3 channels\n",
    "    gray_3_channels[:, :, 0] = gray\n",
    "    gray_3_channels[:, :, 1] = gray\n",
    "    gray_3_channels[:, :, 2] = gray\n",
    "    return gray_3_channels\n",
    "# --------------------------------- The GUI ---------------------------------\n",
    "\n",
    "# First the window layout...2 columns\n",
    "\n",
    "images_col = [[sg.Text('Input file:'), sg.In(enable_events=True, key='-IN FILE-'), sg.FileBrowse()],\n",
    "              [sg.Button('Colorize Photo', key='-PHOTO-'), sg.Button('Save File', key='-SAVE-'), sg.Button('Exit')],\n",
    "              [sg.Image(filename='', key='-IN-'), sg.Image(filename='', key='-OUT-')],]\n",
    "# ----- Full layout -----\n",
    "layout = [[sg.Column(images_col)]]\n",
    "\n",
    "# ----- Make the window -----\n",
    "window = sg.Window('Photo Colorizer', layout, grab_anywhere=True)\n",
    "\n",
    "# ----- Run the Event Loop -----\n",
    "prev_filename = colorized = cap = None\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    if event in (None, 'Exit'):\n",
    "        break\n",
    "    if event == '-PHOTO-':        # Colorize photo button clicked\n",
    "        try:\n",
    "            if values['-IN FILE-']:\n",
    "                filename = values['-IN FILE-']\n",
    "            else:\n",
    "                continue\n",
    "            image, colorized = colorize_image(filename)\n",
    "            window['-IN-'].update(data=cv2.imencode('.png', image)[1].tobytes())\n",
    "            window['-OUT-'].update(data=cv2.imencode('.png', colorized)[1].tobytes())\n",
    "        except:\n",
    "            continue\n",
    "    elif event == '-IN FILE-':      # A single filename was chosen\n",
    "        filename = values['-IN FILE-']\n",
    "        if filename != prev_filename:\n",
    "            prev_filename = filename\n",
    "            try:\n",
    "                image = cv2.imread(filename)\n",
    "                window['-IN-'].update(data=cv2.imencode('.png', image)[1].tobytes())\n",
    "            except:\n",
    "                continue\n",
    "    elif event == '-SAVE-' and colorized is not None:   # Clicked the Save File button\n",
    "        filename = sg.popup_get_file('Save colorized image.\\nColorized image be saved in format matching the extension you enter.', save_as=True)\n",
    "        try:\n",
    "            if filename:\n",
    "                cv2.imwrite(filename, colorized)\n",
    "                sg.popup_quick_message('Image save complete', background_color='red', text_color='white', font='Any 16')\n",
    "        except:\n",
    "            sg.popup_quick_message('ERROR - Image NOT saved!', background_color='red', text_color='white', font='Any 16')\n",
    "# ----- Exit program -----\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "img_color.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
